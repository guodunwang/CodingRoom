高并发的哲学原理	1
前言	1
	写作目标	1
	内容梗概	1
	读者评价	1
	作者信息	2
		吕文翰	2
			高并发系统处理经验	3
			一些微小的成就	3
			开源作品	3
			系列文章	3
		获取作者后续作品	4
版权声明	4
目录	5
第一部分 通用设计方法	8
第1章 高并发问题的通用设计方法	8
	1.1   概述	8
		找出单点，进行拆分	9
		“单点”的定义	9
	1.2   设定目标：每秒一百万次 HTTPS 请求	9
		性能问题要靠架构解决	9
		没有银弹	10
		我们讨论哪个高并发？	10
	1.3   动态、静态资源分开部署	10
		Apache 和 Nginx 的性能差距	10
		加一个 Nginx 软件竟然还能减少 CPU 和内存占用？	10
		使用云服务	11
	1.4   数据库独立部署	12
		将后端代码和数据库部署在同一台机器上是“灾难架构”	12
		MySQL 单独部署时性能非常出色	13
		MySQL 单独部署架构图	13
		运维哲学初探	13
	1.5   真实业务经历：CMS 网站	14
		动静分离	14
		利用 Elasticsearch 提升网页响应速度	14
		MySQL 索引优化	14
		利用 Redis 缓存	14
		网络请求并行化	15
		为什么不做静态化？	15
		反爬措施	15
	1.6   高并发实战：虚拟电商平台“静山”	16
		静态资源云服务化	17
		GraphQL 协议	17
			GraphQL 是最佳的客户端数据交互协议	17
			避免后端工程师的低级错误	18
			GraphQL 可以被看作是一种编程语言的“Java 化”	18
			可以只依靠架构师的个人能力来保证软件质量	18
		数据库分开部署	18
		云数据库的价值	18
	1.7   现实世界中的高并发场景	19
		高并发场景之——电商大促	19
			系统响应慢	19
			订单提交失败	19
			库存超售	19
			支付超时	20
			恶意攻击	20
		高并发场景之——社交网络	20
			缓存优化	21
			异步处理	21
			数据库优化	21
			水平扩展	21
			资源预估和监控	21
		高并发场景之——金融交易	21
		高并发场景之——网络游戏	22
		音频、视频高并发	22
			带宽	22
			延迟	22
			音视频处理	22
	1.8   面试题	23
		No.01：你遇到过哪些高并发系统？	23
		No.02：高并发系统的通用设计方法是什么？	23
		No.03：高并发系统的拆分顺序是什么样的？	24
		No.04：静态资源如何加速？	24
第二部分 计算资源高并发	25
第2章 基础设施并发：虚拟机与 Kubernetes（K8s）	25
	2.1   概述	26
		静山平台流量持续增大，我们该怎样扩容呢？	26
		为何单机只能处理 200 QPS	26
		何为基础设施并发	26
	2.2   服务器虚拟化	27
		资源隔离	27
		提高运维效率	28
		强大的兼容性和可调试能力	29
		高可用架构	29
		利用集群架构提升总体性能	32
			Redis 的单机性能极限	32
			MySQL 的单机性能极限	32
			Elasticsearch 的单机性能极限	33
	2.3   常见虚拟化/仿真技术的软件兼容性	33
		软件的三层兼容性（可移植性）	33
		常见的虚拟化/仿真技术	33
			硬件虚拟化	34
			指令集仿真	34
			运行库虚拟化	35
			虚拟机编程语言	35
			文本解释型编程语言	36
	2.4   容器	36
		容器技术发展史	36
		文件系统隔离：Chroot	36
		进程访问隔离：Namespaces	37
		系统资源限制：Cgroups	37
		应用封装	38
			昙花一现的 LXC	38
			Docker：一夜爆红只需要一个好点子	38
		Docker 的技术优势	38
			镜像技术开天辟地	39
			“以应用为中心”的思想	39
			镜像技术的核心——层	39
			DockerHub 彻底改变了运维的工作性质	40
	2.5   Kubernetes——软件定义计算	40
		Kubernetes 为何会在 2014 年出现	41
		Kernel 的进步	41
			网络的进化	41
			传统虚拟机的时代，几乎只有二层 Overlay 网络可用	41
			Linux 生态中网络的巨大进步	41
			用户需求的变化	42
		Kubernetes 使用软件定义一切的哲学	42
			Kubernetes 相对于虚拟机的优势	42
		“云原生”迷思	43
	2.6   Spring Cloud 是微服务的中间态	43
		Spring Cloud 并不是微服务架构的价值所在	43
		Spring Cloud 和 Kubernetes 关于微服务需求的对应关系	44
	2.7   软件架构本质上是软件维护团队的组织架构	44
		软件工程研究的对象是人	44
		宏内核与微内核	45
	2.8   实战：使用 Docker 部署静山平台	45
		传统思维——打造全功能容器	45
			Dockerfile	45
			生成镜像	48
			基于镜像启动容器	48
			检查运行结果	48
		容器思维——多个容器部署在同一个 Pod 内	49
		平台思维——每个容器一个 Pod	50
	2.9   面试题	52
		No.05：大型项目架构分层的原因是什么？	52
		No.06：系统如何横向扩张？	52
		No.07：K8s 技术比虚拟机技术先进在哪里？	52
第3章 突破编程语言的性能瓶颈	52
	3.1   概述	53
	3.2   互联网系统规模发展史	53
		WWW 的诞生	53
		毫无压力的静态网页时代	54
			Web 1.0 时代最具创新力的企业竟然是必胜客	54
		小有压力的 Web 2.0 时代	54
		同时起飞的电子商务	55
		异军突起的春晚红包	55
	3.3   后端语言变迁史	55
		纯互联网业务喜欢 PHP	55
			扎克伯格选择用 PHP 和 MySQL 搭建了 Facebook	55
			新浪、百度等卖网页广告的公司都选择了 PHP	56
		电商网站几乎全都选择了 Java	56
			美国亚马逊	56
			中国淘宝	56
			其它电商公司	57
			为什么电商网站都用 Java	57
			很多其他业务类型的互联网公司也主要使用 Java	57
		其它昙花一现的后端技术	57
			Python	58
			Ruby	58
			Scala	58
			Node.js	58
		大前端时代	58
		Go：新时代的 PHP	59
	3.4   语言特性如何决定性能	59
		以 PHP 为代表的全阻塞语言	59
		以 Node.js 为代表的非阻塞 I/O	59
		以 Go 语言为代表的协程	60
			Goroutine 的弱点	60
		Redis 是 Go 协程最亲密的伙伴	61
		Node.js 的“多线程”	61
		Java 在语言设计层面的优势	62
		JVM 优秀的设计哲学	62
	3.5   实战：利用 Go 语言的协程开发高性能爬虫	63
		遵守法律法规和 robots.txt 业界规范	63
		笔者的开源项目	63
		爬虫工作流程	63
			1. 设计一个 User-Agent (UA)	63
			2. 选择一个爬虫工具库	63
			3. 设计数据库	64
			4. 星星之火	64
			5. 运行爬虫	64
			6. 合法合规：遵循 robots.txt 规范	67
		基础知识储备：Goroutine 协程	67
		使用协程并发爬取网页	67
		真实的爬虫运行架构图	68
	3.6   面试题	69
		No.08：Node.js 是如何在单线程内实现非阻塞 I/O 的？	69
		No.09：Go 语言为什么快？	69
		No.10：Goroutine 是如何实现高性能的？	70
第三部分 网络资源高并发	71
第4章 至关重要的 Web Server 软件	71
	4.1   Apache——最成功的开源软件之一	72
		互联网的第一声啼哭	72
		CGI 和 HTTPd 的创造者是一个年仅 20 岁的年轻小伙	72
		Apache：驱动人类历史上大部分流量的开源软件	73
		Apache 基金会——最成功的开源软件基金会	73
	4.2   Apache 和 Nginx 性能差异的原因	73
		互联网流量的发展	74
		Kernel 的进步	74
		Nginx 横空出世	74
	4.3   Nginx 与 epoll 的协同工作机制	74
		epoll 的技术原理	75
			1. 网络数据包的处理流程	75
			2. I/O 多路复用的实现方式	76
		epoll 真的是非阻塞的吗？	76
		C10K 问题	77
	4.4   测试三种 Apache 进程模型的技术特点	77
		Apache 的原始并发模型	77
		测试环境	77
			客户端	77
			服务端	78
			相关代码及配置	78
		实验设计	79
			请求计划	79
		为什么这么设计？	79
			标准模式：prefork + mod_php	79
			高性能模式：Nginx + php-fpm	80
			Nginx 反向代理 Apache 模式	81
		结果分析	82
		结论	82
		epoll 和 prefork 的优劣势对比	82
			优势	82
			劣势	82
	4.5   笔者的电商秒杀真实经验	82
		新冠时期的机遇	82
		怎么解决的？	83
	4.6   面试题	83
		No.11：Nginx 为什么比 Apache 性能强？	83
		No.12：epoll 为什么能够处理海量的 TCP 连接？	84
第5章 负载均衡和应用网关	84
	5.1   概述	84
		概念介绍	84
		真实业务架构图	84
	5.2   静山平台如何支持 50000 QPS	85
		京东平峰期并发量估算	85
		Kong 网关需要的硬件规模	86
		Kong 网关	86
		上游服务器（Upstream）的定义	87
		服务发现的概念	87
		什么是应用网关	89
			1. 解放后端架构	89
			2. TLS 卸载	89
			3. 身份验证和安全性提升	89
			4. 指标和数据收集	89
			5. 数据压缩与转换	89
	5.3   单机 Kong 的性能极限	90
		应用网关如何拆分	90
		什么是负载均衡器	91
			低负载下应用网关和负载均衡器可以是同一个软件	91
	5.4   分层的网络	91
		网络是分层的	91
		什么是软件定义网络	92
		应用数据是什么	92
			请求内容	92
			响应内容	93
		HTTP 层之下是 TCP 层	94
			TCP 首部重要数据描述	95
		TCP 层之下是 IP 层	95
		IP 首部包含哪些信息	95
		IP 层之下是 MAC 层(物理层)	96
	5.5   负载均衡器的工作原理	96
		真实世界中 TCP 连接数和 QPS 的比例	96
		单台 Nginx 反向代理的性能极限	96
		使用负载均衡器拆分 TCP 单点	97
		TCP 负载均衡器的工作过程	97
			1. 接收数据（左侧）	98
			2. 发送数据给上游服务器（右侧）	98
			3. 建立映射关系并进行数据转发	99
		为什么负载均衡器性能开销比 Kong 低	99
		Kong 网关需要建立“真·TCP连接”	99
			四层和七层负载均衡（L4/L7）	100
		五万 QPS 下静山平台的架构图	100
	5.6   面试题	100
		No.13：为什么需要做负载均衡？	100
		No.14：如何提升系统的横向扩展能力？	101
		No.15：应用网关在架构中的价值在哪里？	101
		No.16：常见应用网关有哪些区别？	101
第6章 使用软件定义网络（SDN）技术搭建大规模负载均衡集群	101
	6.1   概述	102
		SDN 的运行方式	102
		设定目标：一百万 QPS	102
	6.2   负载均衡发展史	102
		F5 创业史	102
			TMOS 软件平台	102
			迈向应用交付	103
			顺便提一句防火墙	103
		负载均衡一代目：硬件负载均衡	103
		负载均衡二代目：软件负载均衡	104
		价值百万的硬件设备	104
	6.3   交换机	105
		路由器和交换机巨大的价格落差	106
		交换机的工作原理	106
		交换机技术的优缺点	107
	6.4   LVS 技术解析	107
		章文嵩博士创造 IPVS	107
		融入 Linux Kernel	108
		LVS 基本原理	108
		DR 模式数据包推演	108
		DR 模式的特点	109
		LVS 设计思想	110
			内核态	110
		专业的负载均衡协议：OSPF/ECMP	110
			LVS 拆分了网关单点	110
	6.5   Keepalived 高可用	111
		Keepalived 运行原理	111
		高可用 LVS 集群	111
		Keepalived 让众多服务高可用	112
	6.6   突破单台服务器的性能极限：从 20G 到 200G	112
		LVS 单机性能为何会卡在 20G	112
		Linux 网络栈优化	112
			DPDK	112
			网卡芯片硬件卸载	112
		全局锁优化	113
			数据包亲和性优化	113
		性能问题需靠架构解决	113
			1. 拆除 IP 单点：朴素的 DNS	114
			2. 拆除交换机单点：OSPF/ECMP 路由技术	115
			3. 拆除服务器单点：LVS 单机双网卡四网口	115
			4. 天下无单点：全冗余架构	115
		系统容量计算	115
			额外的优势	115
	6.7   殊途共归：硬件厂商的软件设计	116
		负载均衡集群无法单独支撑一百万 QPS	116
	6.8   面试题	117
		No.17：LVS 如何做到高性能？	117
		No.18：负载均衡器是怎样修改数据包的？	117
		No.19：Keepalived 高可用的运行原理？	117
		No.20：如何实现负载均衡的高可用？	118
第四部分 数据库高并发	119
第7章 最难拆的单点：数据库及其背后的存储	119
	7.1   概述	119
	7.2   数据库是个大单点	120
		数据库为何成为单点	120
		数据库是一个极其复杂的软件	121
		数据库的单点，究竟在哪里？	121
			掉电不丢数据是磁盘的重要特性	121
	7.3   存储技术简史	121
		集中式存储	121
		分布式存储	122
		两者之间的差异	122
		集中式存储的优缺点	122
		分布式存储的优缺点	123
			我们正站在 x86 I/O 性能爆发的前夜	123
	7.4   小型机的优势，x86 的劣势：I/O 性能	123
		突飞猛进的 PCIe	123
		全村的希望 CXL	124
			内存、磁盘正在双向奔赴	124
			CXL 补上了“存储器山”上 DDR 内存和 NVMe SSD 之间的巨大空隙	124
			CXL 三代技术发展的终极目标	125
		超高速网卡也需要 CXL 来解决	126
		大语言模型也需要 CXL 技术	126
	7.5   x86 内存技术的演进	127
		内存子系统优化	127
		最近十年内存其实一直在变慢	127
		英特尔对 x86 内存体系的限制	127
	7.6   面试题	127
		No.21：机械磁盘和固态磁盘分别适合什么数据库算法？	127
		No.22：x86 的磁盘性能经过了什么样的发展历程？	128
第8章 MySQL InnoDB 存储引擎详解	128
	还记得我们的目标吗？一百万 QPS	129
	8.1   概述	129
		InnoDB 的发展历程和设计目标	129
		InnoDB 拿什么找信息之神换了什么？	129
			代价	129
			收益	129
	8.2   B+ 树	130
		B+ 树的基本思想	130
		InnoDB 是如何组织数据的	130
			1. 页	130
			2. 索引页里面有什么	131
			3. 数据页里面有什么	132
		SQL 查询过程	133
	8.3   InnoDB 数据插入测试	134
		神奇的“2000W 行分表”历史悬案	134
		测试准备	134
		ibd 结构探测工具	134
		开始插入数据	134
			1. 首次索引分级	135
			2. 二层转换为三层	136
			3. 三层转换为四层	138
		计算页指针id|页号的大小	139
		利用 bigint 确定页号的大小	140
			得出结论：“页号”为 8 字节	140
	8.4   “2000W 行分表”问题	140
		真实世界数据长度及其四层极限	140
			那么四层到五层呢？	141
		2100w 行以后真的会发生性能劣化吗？	141
		那是否意味着不需要再分表了呢？	141
		何时进行分表？	141
	8.5   内存缓存： Buffer Pool	142
	缓存池大小	142
	缓存池基本结构	142
	引入缓存池后的数据读写	143
		缓存池 LRU 算法	143
			预读失效	144
			缓冲池污染	144
		Buffer Pool 应该怎么优化	145
	8.6   面试题	145
		No.23：B+ 树是如何组织数据的？	145
		No.24：InnoDB 为什么适合存储大量数据行？	146
		No.25：缓存 LRU 算法是什么，InnoDB 又做了哪些优化？	146
		No.26：多少行数据以后需要分库分表？	146
第9章 四代分布式数据库的变迁	147
	9.1   单机数据库的不可能三角	147
		为什么不可能	147
		MySQL 选择了哪两个？	147
	9.2   从读写分离到分布式	148
		各种主从架构	148
		分布式数据库	150
	9.3   第一代分布式数据库：中间件	151
		在 MySQL 体系内演进	151
			数据库中间件	151
	9.4   第二代分布式数据库：键值（KV）数据库	152
		分布式时代的“新·不可能三角”	152
		分布式 KV 数据库放弃了事务隔离	153
	9.5   第三代分布式数据库：NewSQL	153
		数据持久性的关键步骤——redo log	155
		事务的两阶段提交	155
			多版本并发控制（MVCC）	155
		Spanner 放弃了什么	155
			Spanner 一致性的根本来源	156
		NewSQL 时代	156
	9.6   第四代分布式数据库：云上数据库	156
		亚马逊 Aurora 开天辟地	156
		计算与存储分离	156
			挖掘云计算的价值点	156
			云计算与特斯拉	157
			计算与存储分离是一种“低成本”技术	157
			计算与存储分离的技术优势	157
			Aurora 的主从同步机制	157
			Aurora 的架构局限	158
		阿里云 PolarDB 后来居上	158
			计算存储分离架构下的整体性能极限	158
			1. 共享的不是 redo log，而是 ibd 文件	158
			2. 绕过内核和网路栈：大幅提升存储性能，降低延迟，减少 CPU 消耗	159
			3. 提出 ParallelRaft 协议，允许部分乱序提交	159
			4. 主从之间基于低延迟的共享存储同步 redo log 数据以刷新 Buffer Pool	159
			5. 单机性能比标准 MySQL 更强	159
			PolarDB 有这么多的优势，那它付出了什么代价呢？	159
		简单讨论一下 CAP 理论	160
	9.7   番外篇	160
		Shared-Nothing、Shared-Memory 和 Shared-Disk	161
		MongoDB 小故事	161
		DBA 晕倒砸烂花盆	161
		列存储思想	161
			列存储数据库 Clickhouse 堪称俄罗斯人暴力美学的典范，和 Nginx 的气质很像	162
	9.8   面试题	162
		No.27：查询请求增加时，如何做数据库的主从分离？	162
		No.28：数据库中间件的基本原理是什么？	162
		No.29：分布式事务如何设计？有哪些关键点？	163
		No.30：Shared-Nothing、Shared-Memory 和 Shared-Disk 有什么异同？	163
		No.31：列存储的原理是什么？适合哪些场景？	163
		No.32：计算与存储分离的优势和劣势分别有哪些？	164
第10章 国产分布式数据库双雄 TiDB 和 OceanBase	164
	10.1   TiDB 的设计思路	164
		TiKV 如何存储数据	165
		TiDB 对 CAP 和不可能三角的抉择	167
	10.2   OceanBase 设计思路	167
		简单的分区	167
		节点存储架构	168
		充分利用内存缓存	169
		直接变身内存数据库	169
		提升并行查询和数据聚合性能	170
		OceanBase 对 CAP 和不可能三角的抉择	170
	10.3   分布式数据库，应该怎么选？	171
		还记得我们的目标吗？五百万数据库 QPS	171
	10.4   面试题	171
		No.33：分布式 CAP 定理讲的是什么？如何推导？	171
		No.34：国产分布式数据库 TiDB 的技术原理是什么？	172
		No.35：国产分布式数据库 OceanBase 的技术原理是什么？	172
		No.36：TiDB 和 OceanBase 分别适合哪些场景？	172
第11章 秒杀系统的两大利器——缓存与队列	173
	11.1   概述	173
		电商秒杀业务的特点	173
		缓存技术的底层原理	173
	11.2   缓存设计实战：静山平台	173
		商品详情接口	173
		库存查询接口	174
		购物车价格计算	174
		下单接口	174
		支付接口	174
		订单状态查询接口	175
		排行榜接口	175
	11.3   缓存的读写策略	175
		原始缓存架构	175
		缓存击穿问题	176
			缓存不过期引发的逻辑悖论	176
		缓存雪崩问题	177
			① 错开过期时间	177
			② 缓存不过期	177
			③ 双 Key 设计	177
			缓存服务器宕机引发的缓存雪崩	177
		缓存后台更新设计	177
			缓存淘汰策略	178
		缓存穿透问题	178
			布隆过滤器的工作原理	179
		缓存预热	179
		缓存高可用	179
		Elasticsearch 的缓存设计方案	180
			页缓存	180
			分片级请求缓存	180
			查询缓存	181
	11.4   秒杀系统的核心——队列	181
		队列解决下单性能问题	181
		队列解决超售问题	181
	11.5   真实的队列秒杀架构——住范儿电商	182
		1. 获取下单令牌	182
		2. 将下单任务插入进队列	182
		3. 队列处理器执行下单任务	182
		4. 第一个 MySQL 事务：扣减 sku 的库存	182
		5. 第二个 MySQL 事务：生成订单	183
		6. 给客户端返回下单结果	183
		为什么要使用两步事务	183
	11.6   缓存和队列的架构意义	183
		缓存的本质是用一致性换取读取性能	183
		队列的本质将关键操作从同步改为异步	184
		消息订阅-架构解耦对高并发系统架构的决定性影响	184
			Kafka 分布式消息订阅系统	184
	11.7   面试题	184
		No.37：如何设计一个每秒一万单的秒杀系统？	184
		No.38：分布式缓存如何保证数据一致性？	184
		No.39：如何解决商品超售问题？	185
		No.40：如何保证消息仅被消费一次？	185
		No.41：如何降低分布式消息队列中消息的延迟？	185
		No.42：Kafka、Hadoop 和 Clickhouse 背后有哪个相同的基本原理？	185
第五部分 无限容量架构	187
第12章 无限容量架构——站在地球表面	187
	12.1   概述	187
		如何定义“一个系统”？	187
	12.2   从业务分库到微服务	188
		数据库调用推演	188
		微服务背后的哲学	188
		微服务照进现实	189
	12.3   削峰	189
		缓存——饮鸩止渴	189
			终极缓存方案	189
		队列——欢迎来到地球	189
		奇技淫巧	190
		现实世界中的削峰	190
	12.4   站在地球表面	190
		基于地理位置对应用和数据库分区	191
		进击的 DNS	192
			类 DNS 哲学思想：Consul 和 Kong	192
		高性能计算第一原则	192
		向 Clickhouse 学习高并发	193
			列式存储	193
			高效压缩	193
			充分利用多 CPU 并行计算	193
			放弃内存缓存	193
			太暴力了，我喜欢	193
		理论无限容量	193
	12.5   番外篇：高可用	194
		熔断	195
		限流	195
		笔者对于设备故障的经验	195
		机房进水导致服务器损坏事件	195
		Facebook 2021年 10 月 4 号宕机	195
	12.6   面试题	196
		No.43：微服务该如何拆分？	196
		No.44：横跨几十个分布式组件的慢请求要如何排查？	196
		No.45：如何设计全链路压测平台？	197
		No.56：Clickhouse 为何能够在一秒内完成上亿行数据的检索？	197
		No.47：什么时候需要限流？什么时候需要熔断？	197
		No.48：如何设计一个跨地区的高可用系统？	198
		No.49：基于地理位置拆分为何成为最流行的高并发系统拆分方案？	198
		No.50：存在一种理论上无限容量的分布式系统吗？	199
其它系列文章	200
2023 年	200
	自己动手开发互联网搜索引擎	200
	写在前面	200
		开源代码地址：https://github.com/johnlui/DIY-Search-Engine	200
	《爬乙己》	201
	本文目标	201
	目录	201
	第一步，编写高性能爬虫，从互联网上爬取网页	202
		爬虫工作流程	202
			1. 设计一个 UA	202
			2. 选择一个爬虫工具库	202
			3. 设计数据库	202
			4. 给爷爬！	203
			5. 合法合规：遵守 robots.txt 规范	205
		制造真正的生产级爬虫	205
			硬件要求	206
			重用 HTTP 客户端以防止内存泄露	207
			基础知识储备：Goroutine 协程	207
			一次取出一批需要爬的 URL，使用协程并发爬	207
		MySQL 性能优化	209
			何以解忧，唯有索引	209
			部分场景下很好用的分库分表	209
			只有一台数据库，应该分表吗？	209
			我的真实硬件和分表逻辑	209
		爬虫数据流和架构优化	210
			拆分仓库表和状态表	210
			实时读取 URL 改为后台定时读取	210
			十分重要的爬虫压力管控	211
			我认为，单线程的 Redis 是 go 协程最佳的伙伴，就像 PHP 和 MySQL 那样。	211
			疯狂使用 Redis 加速频繁重复的数据库调用	212
		生产爬虫遇到的其他问题	213
			抑制暴增的数据库连接数	213
			域名黑名单	213
			复杂的失败处理策略	214
		爬虫运行架构图	214
	第二步，使用倒排索引生成字典	215
		倒排索引到底是什么	215
			还有一个牛逼的词，最小完美哈希，可以用来排布字典数据，加快搜索速度，感兴趣的同学可以自行学习	216
		生成倒排索引数据	216
		使用协程 + Redis 大幅提升词典生成速度	216
			协程分词	216
			使用 Redis 做为词典数据的中转站	217
			使用协程从 Redis 搬运数据到 MySQL 中	217
		事务的妙用：MySQL 高速批量插入	217
		世界的参差：无意义的词	217
	第三步，使用 BM25 算法给出搜索结果	219
		简单介绍一下 BM25 算法	219
		详细讲解 BM25 算法数学表达式的含义	219
			某个词和包含它的某个页面的“相关性权重”	220
			某个词和包含它的某个页面的“相关性得分”	221
			怎么样，是不是比你想象的简单？	222
		检验搜索结果	222
		如何继续提升搜索准确性？	224
		参考资料	224
2018 年	225
	性能之殇	225
	（一）天才冯·诺依曼与冯·诺依曼瓶颈	225
		本文目标	225
		天才 冯·诺依曼	225
		冯·诺依曼架构	226
			优势	226
			冯·诺伊曼瓶颈	226
	（二）分支预测、流水线与多核 CPU	227
		指令流水线	227
			指令流水线，说白了就是 CPU 电路层面的并发。	227
			RISC机器的五层流水线示意图	228
			缺点	228
		分支预测	228
			幸运的是，当下的主流 CPU 在现代编译器的配合下，把这项工作做得越来越好了。	228
		多核 CPU	228
			优势	229
			劣势	229
		怀念过去	229
	（三）通用电子计算机的胎记：事件驱动	229
		通用电子计算机中的事件驱动	230
		事件驱动的实现方式	230
		强大的异常控制流	230
			时间片	230
			虚拟内存	230
			系统调用	230
			硬件中断	231
			进程、线程	231
			编程语言中的 try catch	231
		基于异常控制流的事件驱动	231
			Kqueue	231
			epoll 是什么	231
			epoll 做了什么	231
	（四）Unix 进程模型的局限	231
		Unix 进程模型介绍	232
			上下文切换	232
			上下文切换的过程	232
			名词解释	232
		Unix 进程模型的局限	233
			致命的内存	233
			软件定义一切	233
	（五）DPDK、SDN 与大页内存	234
		软路由	234
			软路由的弱点	234
		SDN	234
			虚拟机	234
			OpenFlow	234
		DPDK	234
			DPDK 是什么	234
			DPDK 的价值	235
		怎么做到的？	235
			用户态网络栈	235
			NUMA	236
		细说大页内存	236
			内存分页	236
			TLB miss	236
			大页内存	237
	（六）现代计算机最亲密的伙伴：局部性与乐观	237
		局部性分类	237
			空间局部性	237
			时间局部性	237
		乐观	237
			乐观的 CPU	237
			乐观的虚拟内存	238
			乐观的缓存	238
			乐观锁	238
			乐观的分布式计算	238
			乐观的代价	238
	（七）分布式计算、超级计算机与神经网络共同的瓶颈	239
		分布式计算的本质	239
			x86 服务器	239
			x86 分布式计算，是一种新的计算机结构。	239
			x86 分布式计算的弱点	239
		x86 分布式计算的基本套路	240
			Google 系大数据处理框架	240
			Redis、MongoDB 的分布式	240
		问题和瓶颈	240
			master 失效问题	241
			系统规模问题	241
		超级计算机	241
		神经网络	241
		九九归一	241
			那么，信息传递速度的瓶颈在哪里呢？	242
	软件工程师需要了解的网络知识：从铜线到 HTTP	242
	起步	242
		写作目标	242
		写作由来	243
			内容来源	243
			为什么是我	243
			说说融会贯通	243
		本文约定	243
	以太网与交换机	243
		网络七层、四层模型	243
		以太网	244
			历史沿革	244
			以太网是什么	244
			双绞线是什么	244
			以太网传递的是什么	244
			一个简化模型	245
			一个关于计算机的常识	245
			结论	245
		交换机	245
			局域网典型拓扑图	245
			以太网帧	246
			解读	246
			交换机工作原理	247
			结论	247
	TCP/IP	247
		那些首部	247
		TCP/IP 概述	248
			我的虚拟化观	248
			TCP/IP 的关系	248
			TCP/IP 和以太网	249
		IP 首部	249
			详解图	249
			简单解释	249
			重要数据描述	249
		结论	250
		TCP 首部	250
			重要数据描述	250
	TCP 和路由器	250
		基础梳理	250
		可靠的 TCP	251
			一个假设	251
			如何实现可靠传输？	251
			三次握手和四次挥手	252
		路由器	253
			路由器	253
			网关	253
			NAT 服务器	254
			DNS 服务器	254
			DHCP 服务器	254
	HTTP 和 HTTPS	254
		HTTP	254
			HTTP 是什么	255
			前提	255
			一个普通的 GET 例子	255
			POST 例子	257
			更多详细解释需要的时候可以自己查，都是明码实价，童叟无欺的。	258
		HTTPS	258
			什么是 TLS	258
			TLS 实现原理	259
			TLS 的局限	260
		总结	261